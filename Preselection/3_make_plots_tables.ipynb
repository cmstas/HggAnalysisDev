{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "from yahist import Hist1D,Hist2D\n",
    "from yahist.utils import plot_stack\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "%pylab inline\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "import mplhep\n",
    "plt.style.use(mplhep.style.CMS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Skim Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "skim_v      = 'v4'  #currently available x3 or v4\n",
    "years       = [ '2016' , '2017' , '2018' ]\n",
    "tot_weights = {}\n",
    "xs          = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2018': {'DYJets': 6529.0,\n",
       "  'ttbar': 831.76,\n",
       "  'ttG': 4.078,\n",
       "  'ttGG': 0.01687,\n",
       "  'ZG': 55.6,\n",
       "  'WG': 191.4,\n",
       "  'GJets_HT40To100': 18640.0,\n",
       "  'GJets_HT100To200': 8631.0,\n",
       "  'GJets_HT200To400': 2185.0,\n",
       "  'GJets_HT400To600': 257.7,\n",
       "  'GJets_HT600ToInf': 85.4,\n",
       "  'QCD_pT30To40': 24810.0,\n",
       "  'QCD_pT40ToInf': 118100.0,\n",
       "  'Diphoton': 84.4,\n",
       "  'ZH': 0.002006453,\n",
       "  'VH': 0.00512,\n",
       "  'signal': 0.0098},\n",
       " '2017': {'DYJets': 6529.0,\n",
       "  'ttbar': 831.76,\n",
       "  'ttG': 4.078,\n",
       "  'ttGG': 0.01687,\n",
       "  'ZG': 55.6,\n",
       "  'WG': 191.4,\n",
       "  'GJets_HT40To100': 18640.0,\n",
       "  'GJets_HT100To200': 8631.0,\n",
       "  'GJets_HT200To400': 2185.0,\n",
       "  'GJets_HT400To600': 257.7,\n",
       "  'GJets_HT600ToInf': 85.4,\n",
       "  'QCD_pT30To40': 24810.0,\n",
       "  'QCD_pT40ToInf': 118100.0,\n",
       "  'Diphoton': 84.4,\n",
       "  'ZH': 0.002006453,\n",
       "  'VH': 0.00512,\n",
       "  'signal': 0.0098},\n",
       " '2016': {'DYJets': 5941.0,\n",
       "  'ttbar': 830.0,\n",
       "  'ttG': 3.819,\n",
       "  'ttGG': 0.01731,\n",
       "  'ZG': 123.8,\n",
       "  'WG': 510.6,\n",
       "  'GJets_HT40To100': 23100.0,\n",
       "  'GJets_HT100To200': 9110.0,\n",
       "  'GJets_HT200To400': 2280.0,\n",
       "  'GJets_HT400To600': 273.0,\n",
       "  'GJets_HT600ToInf': 94.5,\n",
       "  'QCD_pT30To40': 22110.0,\n",
       "  'QCD_pT40ToInf': 113400.0,\n",
       "  'Diphoton': 84.4,\n",
       "  'ZH': 0.002006453,\n",
       "  'VH': 0.00512,\n",
       "  'signal': 0.0098}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('./metadata/xsection_'+skim_v+'.json', \"r\") as f:\n",
    "    xs = json.load(f)\n",
    "xs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2016': {'DYJets': 1464224031091.3281,\n",
       "  'ttbar': 50185035551.38838,\n",
       "  'ttG': 82133236.37131797,\n",
       "  'ttGG': 25098.827877816,\n",
       "  'ZG': 3213875682.239999,\n",
       "  'WG': 22508721524.388016,\n",
       "  'GJets_HT40To100': 9326139.0,\n",
       "  'GJets_HT100To200': 10104155.0,\n",
       "  'GJets_HT200To400': 20527506.0,\n",
       "  'GJets_HT400To600': 5060070.0,\n",
       "  'GJets_HT600ToInf': 5080857.0,\n",
       "  'QCD_pT30To40': 17881707.540976815,\n",
       "  'QCD_pT40ToInf': 12971481.0,\n",
       "  'Diphoton': 27856298.400000002,\n",
       "  'VH': 1862202.4355189996,\n",
       "  'signal': 917722.181297},\n",
       " '2017': {'DYJets': 3023385135017.176,\n",
       "  'ttbar': 297880706283.4699,\n",
       "  'ttG': 93059304.95590399,\n",
       "  'ttGG': 25145.49908388,\n",
       "  'ZG': 3303364320.6753,\n",
       "  'WG': 8273199865.728603,\n",
       "  'GJets_HT40To100': 5570696.0,\n",
       "  'GJets_HT100To200': 9957110.0,\n",
       "  'GJets_HT200To400': 18524305.0,\n",
       "  'GJets_HT400To600': 4640128.0,\n",
       "  'GJets_HT600ToInf': 3278039.0,\n",
       "  'QCD_pT30To40': 14597800.0,\n",
       "  'QCD_pT40ToInf': 18997403.0,\n",
       "  'Diphoton': 21370895.199999996,\n",
       "  'VH': 4100171.4112320007,\n",
       "  'signal': 917906.0},\n",
       " '2018': {'DYJets': 17799598587.564648,\n",
       "  'ttbar': 292228710764.1156,\n",
       "  'ttG': 33778755.65431488,\n",
       "  'ttGG': 25147.44199621101,\n",
       "  'ZG': 4275148495.5808506,\n",
       "  'WG': 9350616834.534428,\n",
       "  'GJets_HT40To100': 7948819.204814303,\n",
       "  'GJets_HT100To200': 9795369.458845828,\n",
       "  'GJets_HT200To400': 17788245.78757894,\n",
       "  'GJets_HT400To600': 4650962.691182763,\n",
       "  'GJets_HT600ToInf': 4970069.563275842,\n",
       "  'QCD_pT30To40': 14597800.0,\n",
       "  'QCD_pT40ToInf': 18997403.0,\n",
       "  'Diphoton': 6074273.1,\n",
       "  'VH': 3800454.18850238,\n",
       "  'signal': 917906.0}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for year in years:\n",
    "    try:\n",
    "        with open('./metadata/totalWeights_'+year+'_'+skim_v+'.json', \"r\") as f:\n",
    "            tot_weights[year] = json.load(f)\n",
    "    except:\n",
    "        print ( ' year: ' , year , ' failed to load weights.')\n",
    "tot_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for each category (e.g. 1lep_1tau) assemble hists from different processes (e.g. signal, diphoton, data...) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['dipho', '0lep_1tau', '0lep_2tau', '1lep_1tau', '2lep_0tau', '1lep_0tau']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#tag = 'basic_dR_mll_cut'\n",
    "tag = 'basic_dR_mll_cut_blind'\n",
    "from glob import glob\n",
    "\n",
    "cat_keys = glob(\"./hists/\" + tag + \"/*\")\n",
    "cat_keys = [cat_keys[i].split(\"/\")[-1] for i in range(len(cat_keys))]\n",
    "cat_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DoubleEG_Run2016B',\n",
       " 'DoubleEG_Run2016C',\n",
       " 'DoubleEG_Run2016D',\n",
       " 'DoubleEG_Run2016E',\n",
       " 'DoubleEG_Run2016F',\n",
       " 'DYJets',\n",
       " 'ttbar',\n",
       " 'ZG',\n",
       " 'WG',\n",
       " 'GJets_HT40To100',\n",
       " 'GJets_HT100To200',\n",
       " 'GJets_HT200To400',\n",
       " 'GJets_HT400To600',\n",
       " 'GJets_HT600ToInf',\n",
       " 'QCD_pT30To40',\n",
       " 'QCD_pT40ToInf',\n",
       " 'Diphoton',\n",
       " 'ZH',\n",
       " 'VH',\n",
       " 'signal',\n",
       " 'DoubleEG_Run2017B',\n",
       " 'DoubleEG_Run2017C',\n",
       " 'DoubleEG_Run2017D',\n",
       " 'DoubleEG_Run2017E',\n",
       " 'DoubleEG_Run2017F',\n",
       " 'EGamma_2018A',\n",
       " 'EGamma_2018B',\n",
       " 'EGamma_2018C',\n",
       " 'EGamma_2018D',\n",
       " 'DoubleEG_Run2016B-2',\n",
       " 'DoubleEG_Run2016G',\n",
       " 'DoubleEG_Run2016H',\n",
       " 'ttG',\n",
       " 'ttGG']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_keys = glob(\"./hists/\" + tag + \"/dipho/*\")\n",
    "process_keys = [process_keys[i].split(\"/\")[-1] for i in range(len(process_keys))]\n",
    "process_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MET_2016_v4.json',\n",
       " 'tautau_SVFit_2016_v4.json',\n",
       " 'tautauL_SVFit_2016_v4.json',\n",
       " 'pho_pT1_2016_v4.json',\n",
       " 'pho_eta1_2016_v4.json',\n",
       " 'pho_eta2_2016_v4.json',\n",
       " 'pho_id1_2016_v4.json',\n",
       " 'pho_id2_2016_v4.json',\n",
       " 'muon_pT1_2016_v4.json',\n",
       " 'muon_phi1_2016_v4.json',\n",
       " 'muon_iso1_2016_v4.json',\n",
       " 'electron_pT1_2016_v4.json',\n",
       " 'n_electron_2016_v4.json',\n",
       " 'tautau_SVFit_2017_v4.json',\n",
       " 'tautauL_SVFit_2017_v4.json',\n",
       " 'pho_pT2_2017_v4.json',\n",
       " 'pho_eta1_2017_v4.json',\n",
       " 'pho_phi2_2017_v4.json',\n",
       " 'pho_id2_2017_v4.json',\n",
       " 'muon_pT1_2017_v4.json',\n",
       " 'muon_phi1_2017_v4.json',\n",
       " 'electron_pT1_2017_v4.json',\n",
       " 'n_electron_2017_v4.json',\n",
       " 'MET_2018_v4.json',\n",
       " 'tautau_SVFit_2018_v4.json',\n",
       " 'tautauA_SVFit_2018_v4.json',\n",
       " 'tautauL_SVFit_2018_v4.json',\n",
       " 'pho_pTom1_2018_v4.json',\n",
       " 'pho_pTom2_2018_v4.json',\n",
       " 'pho_eta1_2018_v4.json',\n",
       " 'pho_eta2_2018_v4.json',\n",
       " 'pho_phi1_2018_v4.json',\n",
       " 'pho_id1_2018_v4.json',\n",
       " 'muon_pT1_2018_v4.json',\n",
       " 'muon_phi1_2018_v4.json',\n",
       " 'n_muon_2018_v4.json',\n",
       " 'electron_eta1_2018_v4.json',\n",
       " 'n_electron_2018_v4.json',\n",
       " 'lepton_pT1_2018_v4.json',\n",
       " 'lepton_eta1_2016_v4.json',\n",
       " 'lepton_eta1_2017_v4.json',\n",
       " 'n_lepton_2016_v4.json',\n",
       " 'electron_pT1_2018_v4.json',\n",
       " 'pho_id2_2018_v4.json',\n",
       " 'pho_phi1_2016_v4.json',\n",
       " 'pho_phi2_2018_v4.json',\n",
       " 'pho_eta2_2017_v4.json',\n",
       " 'pho_id1_2017_v4.json',\n",
       " 'electron_phi1_2016_v4.json',\n",
       " 'pho_phi1_2017_v4.json',\n",
       " 'n_muon_2016_v4.json',\n",
       " 'pho_phi2_2016_v4.json',\n",
       " 'pho_pTom2_2017_v4.json',\n",
       " 'n_muon_2017_v4.json',\n",
       " 'electron_eta1_2016_v4.json',\n",
       " 'pho_pTom2_2016_v4.json',\n",
       " 'pho_pT2_2016_v4.json',\n",
       " 'pho_pTom1_2016_v4.json',\n",
       " 'pho_pTom1_2017_v4.json',\n",
       " 'pho_pT1_2018_v4.json',\n",
       " 'muon_eta1_2017_v4.json',\n",
       " 'muon_iso1_2017_v4.json',\n",
       " 'tautauA_SVFit_2017_v4.json',\n",
       " 'electron_phi1_2017_v4.json',\n",
       " 'MET_2017_v4.json',\n",
       " 'pho_pT2_2018_v4.json',\n",
       " 'muon_eta1_2016_v4.json',\n",
       " 'electron_iso1_2017_v4.json',\n",
       " 'tautauA_SVFit_2016_v4.json',\n",
       " 'electron_iso1_2016_v4.json',\n",
       " 'pho_pT1_2017_v4.json',\n",
       " 'muon_eta1_2018_v4.json',\n",
       " 'muon_iso1_2018_v4.json',\n",
       " 'electron_eta1_2017_v4.json',\n",
       " 'electron_phi1_2018_v4.json',\n",
       " 'electron_iso1_2018_v4.json',\n",
       " 'lepton_pT1_2016_v4.json',\n",
       " 'lepton_pT1_2017_v4.json',\n",
       " 'lepton_eta1_2018_v4.json',\n",
       " 'lepton_phi1_2016_v4.json',\n",
       " 'lepton_phi1_2017_v4.json',\n",
       " 'lepton_phi1_2018_v4.json',\n",
       " 'lepton_iso1_2016_v4.json',\n",
       " 'lepton_iso1_2017_v4.json',\n",
       " 'lepton_iso1_2018_v4.json',\n",
       " 'n_lepton_2017_v4.json',\n",
       " 'n_lepton_2018_v4.json']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hist_keys = glob(\"./hists/\" + tag + '/1lep_0tau/signal/*'+skim_v+'.json')\n",
    "hist_keys = [hist_keys[i].split(\"/\")[-1] for i in range(len(hist_keys))]\n",
    "#hist_keys = [ 'pho_pT1_2016_v4.json' , 'pho_pT1_2017_v4.json', 'pho_pT1_2018_v4.json' ]\n",
    "hist_keys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge muon and electron into lep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def merge_lep(tag, cat):\n",
    "    ## 0tau_1lep\n",
    "    hists_to_merge = [\"muon_pT1\", \"muon_eta1\", \"muon_phi1\", \"muon_iso1\", \"n_muon\"]\n",
    "    for name in hists_to_merge:\n",
    "        process_names = glob(\"./hists/\" + tag + \"/\" + cat + \"/*\")\n",
    "        process_names = [process_names[i].split(\"/\")[-1] for i in range(len(process_names))]\n",
    "        \n",
    "        #hists_merged = {}\n",
    "        for process in process_names:\n",
    "            for year in years:\n",
    "                histname = \"./hists/\" + tag + \"/\" + cat + \"/\" + process + \"/\" + name + '_' + year + '_' + skim_v + \".json\"\n",
    "                if not os.path.isfile(histname): continue\n",
    "                if not os.path.isfile(histname.replace(\"muon\", \"electron\")): continue\n",
    "                hist_muon = Hist1D.from_json(histname)\n",
    "                hist_ele = Hist1D.from_json(histname.replace(\"muon\", \"electron\")) \n",
    "                \n",
    "                hist_lep = hist_muon + hist_ele\n",
    "                hist_lep.to_json(histname.replace(\"muon\", \"lepton\"))\n",
    "    \n",
    "## 1tau_1lep\n",
    "merge_lep( tag , \"1lep_0tau\")\n",
    "merge_lep( tag , \"1lep_1tau\")\n",
    "\n",
    "for process in process_keys:\n",
    "    for year in years:\n",
    "        h_dR_name_e  = \"./hists/\" + tag + \"/1lep_1tau/\" + process + \"/dR_tau_e\" +'_' + year +'_'+ skim_v+\".json\"\n",
    "        h_dR_name_mu = \"./hists/\" + tag + \"/1lep_1tau/\" + process + \"/dR_tau_mu\"+'_' + year +'_'+ skim_v+\".json\"\n",
    "        h_m_name_e   = \"./hists/\" + tag + \"/1lep_1tau/\" + process + \"/mtaue\"    +'_' + year +'_'+ skim_v+\".json\"\n",
    "        h_m_name_mu  = \"./hists/\" + tag + \"/1lep_1tau/\" + process + \"/mtaumu\"   +'_' + year +'_'+ skim_v+\".json\"\n",
    "        \n",
    "        if not os.path.isfile(h_dR_name_e): continue\n",
    "        if not os.path.isfile(h_dR_name_mu): continue\n",
    "        if not os.path.isfile(h_m_name_e): continue\n",
    "        if not os.path.isfile(h_m_name_mu): continue\n",
    "            \n",
    "        dR_tau_e = Hist1D.from_json(h_dR_name_e)\n",
    "        dR_tau_mu = Hist1D.from_json(h_dR_name_mu)\n",
    "        dR_tau_lep = dR_tau_e + dR_tau_mu\n",
    "        \n",
    "        mtaue = Hist1D.from_json(h_m_name_e)\n",
    "        mtaumu = Hist1D.from_json(h_m_name_mu)\n",
    "        mtaulep = mtaue + mtaumu\n",
    "        \n",
    "        dR_tau_lep.to_json(h_dR_name_e.replace(\"tau_e\", \"tau_lep\"))\n",
    "        mtaulep.to_json(h_m_name_e.replace(\"taue\", \"taulep\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "xlabel = {\n",
    "    \"pho_pT1\": \"$p_T^{\\gamma 1} (GeV)$\",\n",
    "    \"pho_pT2\": \"$p_T^{\\gamma 2} (GeV)$\",\n",
    "    \"pho_pTom1\": \"$(p_T/m_{\\gamma\\gamma})^{\\gamma 1} (GeV)$\",\n",
    "    \"pho_pTom2\": \"$(p_T/m_{\\gamma\\gamma})^{\\gamma 2} (GeV)$\",\n",
    "    \"pho_eta1\": \"$\\eta^{\\gamma 1}$\",\n",
    "    \"pho_eta2\": \"$\\eta^{\\gamma 2}$\",\n",
    "    \"pho_phi1\": \"$\\phi^{\\gamma 1}$\",\n",
    "    \"pho_phi2\": \"$\\phi^{\\gamma 2}$\",\n",
    "    \"pho_id1\": \"$ID^{\\gamma 1}$\",\n",
    "    \"pho_id2\": \"$ID^{\\gamma 2}$\",\n",
    "    \"tau_pT1\": \"$p_T^{tau 1} (GeV)$\",\n",
    "    \"tau_pT2\": \"$p_T^{tau 2} (GeV)$\",\n",
    "    \"tau_eta1\": \"$\\eta^{tau 1}$\",\n",
    "    \"tau_eta2\": \"$\\eta^{tau 2}$\",\n",
    "    \"tau_phi1\": \"$\\phi^{tau 1}$\",\n",
    "    \"tau_phi2\": \"$\\phi^{tau 2}$\",\n",
    "    \"tau_deeptau_vs_j_1\": \"deepTau vs $j^{tau 1}$\",\n",
    "    \"tau_deeptau_vs_j_2\": \"deepTau vs $j^{tau 2}$\",\n",
    "    \"tau_deeptau_vs_m_1\": \"deepTau vs $m^{tau 1}$\",\n",
    "    \"tau_deeptau_vs_m_2\": \"deepTau vs $m^{tau 2}$\",\n",
    "    \"tau_deeptau_vs_e_1\": \"deepTau vs $e^{tau 1}$\",\n",
    "    \"tau_deeptau_vs_e_2\": \"deepTau vs $e^{tau 2}$\",\n",
    "    \"electron_pT1\": \"$p_T^{electron 1} (GeV)$\",\n",
    "    \"electron_pT2\": \"$p_T^{electron 2} (GeV)$\",\n",
    "    \"electron_eta1\": \"$\\eta^{electron 1}$\",\n",
    "    \"electron_eta2\": \"$\\eta^{electron 2}$\",\n",
    "    \"electron_phi1\": \"$\\phi^{electron 1}$\",\n",
    "    \"electron_phi2\": \"$\\phi^{electron 2}$\",\n",
    "    \"electron_iso1\": \"$iso^{electron 1}$\",\n",
    "    \"electron_iso2\": \"$iso^{electron 2}$\",\n",
    "    \"muon_pT1\": \"$p_T^{\\mu 1} (GeV)$\",\n",
    "    \"muon_pT2\": \"$p_T^{\\mu 2} (GeV)$\",\n",
    "    \"muon_eta1\": \"$\\eta^{\\mu 1}$\",\n",
    "    \"muon_eta2\": \"$\\eta^{\\mu 2}$\",\n",
    "    \"muon_phi1\": \"$\\phi^{\\mu 1}$\",\n",
    "    \"muon_phi2\": \"$\\phi^{\\mu 2}$\",\n",
    "    \"muon_iso1\": \"$iso^{\\mu 1}$\",\n",
    "    \"muon_iso2\": \"$iso^{\\mu 2}$\",\n",
    "    \"lepton_pT1\": \"$p_T^{lepton 1} (GeV)$\",\n",
    "    \"lepton_pT2\": \"$p_T^{lepton 2} (GeV)$\",\n",
    "    \"lepton_eta1\": \"$\\eta^{lepton 1}$\",\n",
    "    \"lepton_eta2\": \"$\\eta^{lepton 2}$\",\n",
    "    \"lepton_phi1\": \"$\\phi^{lepton 1}$\",\n",
    "    \"lepton_phi2\": \"$\\phi^{lepton 2}$\",\n",
    "    \"lepton_iso1\": \"$iso^{lepton 1}$\",\n",
    "    \"lepton_iso2\": \"$iso^{lepton 2}$\",\n",
    "    \"n_tau\": \"$n_{tau}$\",\n",
    "    \"n_muon\": \"$n_{\\mu}$\",\n",
    "    \"n_electron\": \"$n_{electron}$\",\n",
    "    \"n_lepton\": \"$n_{lepton}$\",\n",
    "    \"dR_tau_e\": \"$dR(tau,e)$\",\n",
    "    \"dR_tau_mu\": \"$dR(tau,\\mu)$\",\n",
    "    \"dR_tau_lep\": \"$dR(tau,lepton)$\",\n",
    "    \"dR_tautau\": \"$dR(tau,tau)$\",\n",
    "    \"dR_ee\": \"$dR(e,e)$\",\n",
    "    \"dR_mumu\": \"$dR(\\mu,\\mu)$\",\n",
    "    \"mtaue\": \"$m_{tau e}$ (GeV)\",\n",
    "    \"mtaumu\": \"$m_{tau \\mu} (GeV)$\",\n",
    "    \"mee\": \"$m_{ee} (GeV)$\",\n",
    "    \"mmumu\": \"$m_{\\mu\\mu} (GeV)$\",\n",
    "    \"mtaulep\": \"$m_{tau lep} (GeV)$\",\n",
    "    \"mtautau\": \"$m_{tau tau} (GeV)$\",\n",
    "    \"tautau_SVFit\": \"$m_{tau tau}^{SVfit} (GeV)$\",\n",
    "    \"tautauA_SVFit\": \"$m_{tau tau}^{SVfit} (GeV)$\",\n",
    "    \"tautauL_SVFit\": \"$m_{tau tau}^{SVfit} (GeV)$\",\n",
    "    \"MET\": \"MET $p_{T} (GeV)$\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = {\n",
    "    \n",
    "    'ZG'      : \"#E4892F\" ,\n",
    "    'QCD'     : \"#5757E6\",\n",
    "    'GJets'   : \"#57E661\",\n",
    "    'ttX'     : \"#6F57E6\",\n",
    "    'VH'      : '#2fdbe4',\n",
    "    'Diphoton': \"#E6576F\" ,\n",
    "    'WG'      : \"#9A57E6\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from glob import glob\n",
    "from datetime import date\n",
    "from subprocess import call\n",
    "\n",
    "#lumi = 59.0\n",
    "#luminosities from http://www.t2.ucsd.edu/tastwiki/bin/view/CMS/HHGgTauTauSamples#List_of_data\n",
    "lumi = { \n",
    "    '2016' : 42.3      ,\n",
    "    '2017' : 41.6      ,\n",
    "    '2018' : 59.9\n",
    "}\n",
    "\n",
    "\n",
    "def get_data_mc_plot(tag, cat, hist_name, year, savetag):\n",
    "    # deal with one data/MC plot (e.g. photon pT) for one process (e.g. 1lep_1tau)\n",
    "    process_names = glob(\"./hists/\" + tag + \"/\" + cat + \"/*\")\n",
    "    process_names = [process_names[i].split(\"/\")[-1] for i in range(len(process_names))]\n",
    "    \n",
    "    hists = {}\n",
    "    norms = {}\n",
    "    norm_errors = {}\n",
    "    ## gather all hists from different processes and years\n",
    "    for process in process_names:\n",
    "        if process == 'ZH': continue\n",
    "        #if \"DY\" or \"WG\" in process: continue\n",
    "        hist = \"./hists/\" + tag + \"/\" + cat + \"/\" + process + \"/\" + hist_name + '_' + year + '_' + skim_v + '.json'\n",
    "        if not os.path.isfile(hist): continue\n",
    "        hists[process] = Hist1D.from_json(hist)\n",
    "        if ( 'EGamma' not in process and 'DoubleEG' not in process ):\n",
    "            hists[process] = hists[process]/tot_weights[year][process]*lumi[year]*1000*xs[year][process]\n",
    "            hists[process].metadata[\"label\"] = process\n",
    "    \n",
    "    \n",
    "    # data\n",
    "    hist_data = np.sum( [hists[key] for key in hists.keys() if ( 'EGamma' in key or 'DoubleEG' in key ) ] )\n",
    "    norms[\"data\"] = hist_data.integral\n",
    "    norm_errors[\"data\"] = hist_data.integral_error\n",
    "    hist_MC = [] #[hist_GJets, hist_QCD]\n",
    "    \n",
    "    # GJets\n",
    "    hist_GJets = np.sum( [hists[key] for key in hists.keys() if \"GJet\" in key] )\n",
    "    if type(hist_GJets) == Hist1D:\n",
    "        hist_GJets.metadata[\"label\"] = \"GJets\"\n",
    "        hist_GJets.metadata[\"color\"] = colors[\"GJets\"]\n",
    "        if cat != \"0lep_2tau\":\n",
    "            hist_MC.append(hist_GJets)\n",
    "        norms[\"GJet\"] = hist_GJets.integral\n",
    "        norm_errors[\"GJet\"] = hist_GJets.integral_error\n",
    "        \n",
    "    # QCD\n",
    "    hist_QCD = np.sum( [hists[key] for key in hists.keys() if \"QCD\" in key] )\n",
    "    if type(hist_QCD) == Hist1D:\n",
    "        hist_QCD.metadata[\"label\"] = \"QCD\"\n",
    "        hist_QCD.metadata[\"color\"] = colors[\"QCD\"]\n",
    "        hist_MC.append(hist_QCD)\n",
    "        norms[\"QCD\"] = hist_QCD.integral\n",
    "        norm_errors[\"QCD\"] = hist_QCD.integral_error\n",
    " \n",
    "    # ttX\n",
    "    hist_ttX = np.sum( [hists[key] for key in hists.keys() if \"tt\" in key] )\n",
    "    if type(hist_ttX) == Hist1D:\n",
    "        hist_ttX.metadata[\"label\"] = \"ttX\"\n",
    "        hist_ttX.metadata[\"color\"] = colors[\"ttX\"]\n",
    "        hist_MC.append(hist_ttX)\n",
    "        norms[\"ttX\"] = hist_ttX.integral\n",
    "        norm_errors[\"ttX\"] = hist_ttX.integral_error\n",
    "    \n",
    "    \n",
    "    # other MC\n",
    "    others_blacklist = ['EGamma', 'DoubleEG', 'GJet', 'QCD', 'tt' , 'signal', 'DYJets']\n",
    "    for key in hists.keys():\n",
    "        skip = False\n",
    "        for forbid_key in others_blacklist:\n",
    "            if forbid_key in key:\n",
    "                skip = True\n",
    "                break\n",
    "        if skip: continue\n",
    "        hist_MC.append(hists[key])\n",
    "        hists[key].metadata[\"color\"] = colors[key]\n",
    "        norms[key] = hists[key].integral\n",
    "        norm_errors[key] = hists[key].integral_error\n",
    "        \n",
    "    # sum all bkg, for ratio plot\n",
    "    hist_bkg = np.sum(hist_MC)\n",
    "    norms[\"bkg\"] = hist_bkg.integral\n",
    "    norm_errors[\"bkg\"] = hist_bkg.integral_error\n",
    "    \n",
    "    \n",
    "    fig,(ax1,ax2) = plt.subplots(2,sharex=True,figsize=(12,9),gridspec_kw=dict(height_ratios=[3, 1]))\n",
    "    hist_data.plot(ax=ax1,histtype=\"step\", label=\"data\", show_errors=True, color=\"black\")\n",
    "    hists[\"signal\"].plot(ax=ax1,histtype=\"step\", fill = False, label=\"signal\", color=\"red\")\n",
    "    norms[\"signal\"] = hists[\"signal\"].integral\n",
    "    norm_errors[\"signal\"] = hists[\"signal\"].integral_error\n",
    "    plot_stack(hist_MC,ax=ax1)\n",
    "    ax1.set_ylim(0)\n",
    "    \n",
    "    (hist_data/hist_bkg).plot(ax=ax2,show_errors=True,label=\"data/MC\")\n",
    "    ax2.set_ylim(0.5,1.5)\n",
    "    \n",
    "    # guided horizontal line\n",
    "    xmin, xmax = ax1.get_xlim()\n",
    "    ax2.hlines(y=1, xmin = xmin, xmax = xmax, linewidth=2, color='r')\n",
    "    \n",
    "    basepath = \"/home/users/fsetti/public_html/HH2ggtautau/data_mc/\" + today + \"_\" + savetag + \"/\"\n",
    "    savepath = basepath + cat + \"/\" \n",
    "    call(\"mkdir -p \" + savepath, shell=True)\n",
    "    call(\"cp /home/users/fsetti/scripts/index.php \" + savepath, shell=True)\n",
    "    ax2.set_xlabel(xlabel[hist_name.split('.')[0]])\n",
    "    \n",
    "    save_name = hist_name.split(\".\")[0] + '_' + year + '_' + skim_v\n",
    "    plt.savefig(savepath + save_name + \".pdf\")\n",
    "    plt.savefig(savepath + save_name + \".png\")\n",
    "    plt.close()\n",
    "    \n",
    "    with open(savepath + save_name + \"_norm.json\", \"w\") as f:\n",
    "        data = json.dump(norms, f)\n",
    "    with open(savepath + save_name  + \"_normerror.json\", \"w\") as f:\n",
    "        data = json.dump(norm_errors, f)\n",
    "    #return norms, norm_errors\n",
    "    \n",
    "#get_data_mc_plot( tag , '1lep_1tau', 'mtaulep', '2017' , 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge 2016, 2017 and 2018"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "today = str(date.today())\n",
    "\n",
    "def merge_data_mc_plot(tag, cat, hist_name, savetag):\n",
    "    # deal with one data/MC plot (e.g. photon pT) for one process (e.g. 1lep_1tau)\n",
    "    process_names = glob(\"./hists/\" + tag + \"/\" + cat + \"/*\")\n",
    "    process_names = [process_names[i].split(\"/\")[-1] for i in range(len(process_names))]\n",
    "    \n",
    "    hists = {}\n",
    "    norms = {}\n",
    "    norm_errors = {}\n",
    "    ## gather all hists from different processes and years\n",
    "    for process in process_names:\n",
    "        if process == 'ZH': continue\n",
    "        #if \"DY\" or \"WG\" in process: continue\n",
    "        hist_2016 = \"./hists/\" + tag + \"/\" + cat + \"/\" + process + \"/\" + hist_name.replace('2017', '2016') + '_' + skim_v + '.json'\n",
    "        hist_2017 = \"./hists/\" + tag + \"/\" + cat + \"/\" + process + \"/\" + hist_name + '_' + skim_v + '.json'\n",
    "        hist_2018 = \"./hists/\" + tag + \"/\" + cat + \"/\" + process + \"/\" + hist_name.replace('2017', '2018') + '_' + skim_v + '.json'\n",
    "        \n",
    "        if os.path.isfile(hist_2016): \n",
    "            hist_2016 = Hist1D.from_json(hist_2016)\n",
    "            if ( 'EGamma' not in process and 'DoubleEG' not in process ):\n",
    "                hist_2016 = hist_2016/tot_weights['2016'][process]*lumi['2016']*1000*xs['2016'][process]\n",
    "        \n",
    "        if os.path.isfile(hist_2017): \n",
    "            hist_2017 = Hist1D.from_json(hist_2017)\n",
    "            if ( 'EGamma' not in process and 'DoubleEG' not in process ):\n",
    "                hist_2017 = hist_2017/tot_weights['2017'][process]*lumi['2017']*1000*xs['2017'][process]\n",
    "        \n",
    "        if os.path.isfile(hist_2018): \n",
    "            hist_2018 = Hist1D.from_json(hist_2018)\n",
    "            if ( 'EGamma' not in process and 'DoubleEG' not in process ):\n",
    "                hist_2018 = hist_2018/tot_weights['2018'][process]*lumi['2018']*1000*xs['2018'][process]\n",
    "        \n",
    "        if ( type(hist_2016) == Hist1D or type(hist_2017) == Hist1D or type(hist_2018) == Hist1D ):\n",
    "            hists[process] = np.sum( [hist for hist in [hist_2016,hist_2017,hist_2018] if type(hist) == Hist1D ] )\n",
    "            hists[process].metadata[\"label\"] = process\n",
    "    \n",
    "    # data\n",
    "    hist_data = np.sum( [hists[key] for key in hists.keys() if ( 'EGamma' in key or 'DoubleEG' in key ) ] )\n",
    "    norms[\"data\"] = hist_data.integral\n",
    "    norm_errors[\"data\"] = hist_data.integral_error\n",
    "    hist_MC = [] #[hist_GJets, hist_QCD]\n",
    "    \n",
    "    # GJets\n",
    "    hist_GJets = np.sum( [hists[key] for key in hists.keys() if \"GJet\" in key] )\n",
    "    if type(hist_GJets) == Hist1D:\n",
    "        hist_GJets.metadata[\"label\"] = \"GJets\"\n",
    "        hist_GJets.metadata[\"color\"] = colors[\"GJets\"]\n",
    "        if cat != \"0lep_2tau\":\n",
    "            hist_MC.append(hist_GJets)\n",
    "        norms[\"GJet\"] = hist_GJets.integral\n",
    "        norm_errors[\"GJet\"] = hist_GJets.integral_error\n",
    "        \n",
    "    # QCD\n",
    "    hist_QCD = np.sum( [hists[key] for key in hists.keys() if \"QCD\" in key] )\n",
    "    if type(hist_QCD) == Hist1D:\n",
    "        hist_QCD.metadata[\"label\"] = \"QCD\"\n",
    "        hist_QCD.metadata[\"color\"] = colors[\"QCD\"]\n",
    "        hist_MC.append(hist_QCD)\n",
    "        norms[\"QCD\"] = hist_QCD.integral\n",
    "        norm_errors[\"QCD\"] = hist_QCD.integral_error\n",
    " \n",
    "    # ttX\n",
    "    hist_ttX = np.sum( [hists[key] for key in hists.keys() if \"tt\" in key] )\n",
    "    if type(hist_ttX) == Hist1D:\n",
    "        hist_ttX.metadata[\"label\"] = \"ttX\"\n",
    "        hist_ttX.metadata[\"color\"] = colors[\"ttX\"]\n",
    "        hist_MC.append(hist_ttX)\n",
    "        norms[\"ttX\"] = hist_ttX.integral\n",
    "        norm_errors[\"ttX\"] = hist_ttX.integral_error\n",
    "    \n",
    "    \n",
    "    # other MC\n",
    "    others_blacklist = ['EGamma', 'DoubleEG', 'GJet', 'QCD', 'tt' , 'signal', 'DYJets']\n",
    "    for key in hists.keys():\n",
    "        skip = False\n",
    "        for forbid_key in others_blacklist:\n",
    "            if forbid_key in key:\n",
    "                skip = True\n",
    "                break\n",
    "        if skip: continue\n",
    "        hist_MC.append(hists[key])\n",
    "        hists[key].metadata[\"color\"] = colors[key]\n",
    "        norms[key] = hists[key].integral\n",
    "        norm_errors[key] = hists[key].integral_error\n",
    "        \n",
    "    # sum all bkg, for ratio plot\n",
    "    hist_bkg = np.sum(hist_MC)\n",
    "    norms[\"bkg\"] = hist_bkg.integral\n",
    "    norm_errors[\"bkg\"] = hist_bkg.integral_error\n",
    "    \n",
    "    fig,(ax1,ax2) = plt.subplots(2,sharex=True,figsize=(12,9),gridspec_kw=dict(height_ratios=[3, 1]))\n",
    "    hist_data.plot(ax=ax1,histtype=\"step\", label=\"data\", show_errors=True, color=\"black\")\n",
    "    hists[\"signal\"].plot(ax=ax1,histtype=\"step\", fill = False, label=\"signal\", color=\"red\")\n",
    "    norms[\"signal\"] = hists[\"signal\"].integral\n",
    "    norm_errors[\"signal\"] = hists[\"signal\"].integral_error\n",
    "    plot_stack(hist_MC,ax=ax1)\n",
    "    ax1.set_ylim(0)\n",
    "    \n",
    "    (hist_data/hist_bkg).plot(ax=ax2,show_errors=True,label=\"data/MC\")\n",
    "    ax2.set_ylim(0.5,1.5)\n",
    "    \n",
    "    # guided horizontal line\n",
    "    xmin, xmax = ax1.get_xlim()\n",
    "    ax2.hlines(y=1, xmin = xmin, xmax = xmax, linewidth=2, color='r')\n",
    "    \n",
    "    basepath = \"/home/users/fsetti/public_html/HH2ggtautau/data_mc/\" + today + \"_\" + savetag + \"/\"\n",
    "    savepath = basepath + cat + \"/\" \n",
    "    call(\"mkdir -p \" + savepath, shell=True)\n",
    "    call(\"cp /home/users/fsetti/scripts/index.php \" + savepath, shell=True)\n",
    "    ax2.set_xlabel(xlabel[hist_name.split('.')[0].split('_201')[0]])\n",
    "    \n",
    "    save_name = hist_name.split(\".\")[0].replace('_2017', '_') + skim_v\n",
    "    plt.savefig(savepath + save_name + \".pdf\")\n",
    "    plt.savefig(savepath + save_name + \".png\")\n",
    "    plt.close()\n",
    "    \n",
    "    with open(savepath + save_name + \"_norm.json\", \"w\") as f:\n",
    "        data = json.dump(norms, f)\n",
    "    with open(savepath + save_name  + \"_normerror.json\", \"w\") as f:\n",
    "        data = json.dump(norm_errors, f)\n",
    "    #return norms, norm_errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dipho 11/02/2021 13:57:29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.\n",
      "'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.\n",
      "'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.\n",
      "'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0lep_1tau 11/02/2021 13:57:34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.\n",
      "'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.\n",
      "'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.\n",
      "'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0lep_2tau 11/02/2021 13:57:38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.\n",
      "'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.\n",
      "'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.\n",
      "'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1lep_1tau 11/02/2021 13:57:43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.\n",
      "'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.\n",
      "'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.\n",
      "'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2lep_0tau 11/02/2021 13:57:47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.\n",
      "'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.\n",
      "'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.\n",
      "'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1lep_0tau 11/02/2021 13:57:52\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.\n",
      "'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.\n",
      "'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.\n",
      "'texgyreheros-regular.otf' can not be subsetted into a Type 3 font. The entire font will be embedded in the output.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.1 s, sys: 2.32 s, total: 26.4 s\n",
      "Wall time: 27.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def gather_hists(tag, savetag):\n",
    "    \n",
    "    from datetime import datetime\n",
    "    cat_keys = glob(\"./hists/\" + tag + \"/*\")\n",
    "    cat_keys = [cat_keys[i].split(\"/\")[-1] for i in range(len(cat_keys))]\n",
    "    \n",
    "    for cat in cat_keys:\n",
    "        now = datetime.now()\n",
    "        print (cat, now.strftime(\"%d/%m/%Y %H:%M:%S\"))\n",
    "    \n",
    "        hist_names = glob('./hists/' + tag + '/' + cat + '/signal/*'+'_'+skim_v+'.json')\n",
    "        hist_names = list(set([hist_names[i].split(\"/\")[-1].split('_'+skim_v)[0] for i in range(len(hist_names))]))\n",
    "        hist_names = [ hist_name for hist_name in hist_names if '2017' in hist_name ]\n",
    "        hist_names = [ hist_name for hist_name in hist_names if 'pho_pT1_' in hist_name ]\n",
    "        for hist_name in hist_names:\n",
    "            for year in years:\n",
    "                get_data_mc_plot(tag, cat, hist_name.split('_201')[0], year, savetag)\n",
    "            merge_data_mc_plot( tag , cat , hist_name, savetag )\n",
    "\n",
    "\n",
    "save_tag = 'blind'\n",
    "gather_hists( tag , save_tag )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "drwxr-xr-x+ 8 fsetti fsetti 4.0K Feb  8 23:46 2021-02-08_blind\n",
      "drwxr-xr-x+ 8 fsetti fsetti 4.0K Feb  9 19:20 2021-02-09_blind\n",
      "drwxr-xr-x+ 8 fsetti fsetti 4.0K Feb 10 17:03 2021-02-10_blind\n",
      "drwxr-xr-x+ 8 fsetti fsetti 4.0K Feb 11 01:15 2021-02-11_blind\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "chmod -R 755 /home/users/fsetti/public_html/HH2ggtautau/data_mc/\n",
    "ls -lrht /home/users/fsetti/public_html/HH2ggtautau/data_mc/ | tail -n 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|-\n",
      "| | dipho|1lep_0tau|0lep_1tau|1lep_1tau|0lep_2tau|2lep_0tau\n",
      "|-\n",
      "|-\n",
      "| GJet | 623155.33 $\\pm$ 7275.42|629.30 $\\pm$ 185.40|7575.98 $\\pm$ 743.52|0.79 $\\pm$ 0.79|0.00 $\\pm$ 0.00|1.08 $\\pm$ 1.08\n",
      "| QCD | 697650.86 $\\pm$ 15135.22|1109.39 $\\pm$ 640.51|5948.41 $\\pm$ 1410.16|0.00 $\\pm$ 0.00|0.00 $\\pm$ 0.00|0.00 $\\pm$ 0.00\n",
      "| ttX | 6458.70 $\\pm$ 164.79|673.62 $\\pm$ 46.23|171.34 $\\pm$ 20.21|7.40 $\\pm$ 2.50|0.19 $\\pm$ 0.26|20.03 $\\pm$ 7.70\n",
      "| ZG | 6515.72 $\\pm$ 55.39|471.69 $\\pm$ 14.56|208.51 $\\pm$ 9.53|6.02 $\\pm$ 1.41|6.98 $\\pm$ 1.44|159.77 $\\pm$ 8.09\n",
      "| WG | 16094.15 $\\pm$ 156.48|873.21 $\\pm$ 36.08|221.78 $\\pm$ 18.80|1.86 $\\pm$ 1.35|-0.72 $\\pm$ 0.72|-0.57 $\\pm$ 0.57\n",
      "| Diphoton | 290600.03 $\\pm$ 263.37|501.94 $\\pm$ 9.93|5025.94 $\\pm$ 30.89|2.37 $\\pm$ 0.54|12.36 $\\pm$ 1.26|26.66 $\\pm$ 2.07\n",
      "|-\n",
      "| bkg | 1640642.56 $\\pm$ 16796.74|4278.24 $\\pm$ 669.61|19158.10 $\\pm$ 1594.73|18.57 $\\pm$ 3.31|18.90 $\\pm$ 2.06|209.35 $\\pm$ 11.43\n",
      "| data | 1435254.00 $\\pm$ 1198.02|3798.00 $\\pm$ 61.63|16906.00 $\\pm$ 130.02|13.00 $\\pm$ 3.61|21.00 $\\pm$ 4.58|160.00 $\\pm$ 12.65\n",
      "|-\n",
      "| signal | 625.64 $\\pm$ 0.57|100.22 $\\pm$ 0.23|192.77 $\\pm$ 0.32|32.08 $\\pm$ 0.13|28.80 $\\pm$ 0.12|8.90 $\\pm$ 0.07\n",
      "|-\n"
     ]
    }
   ],
   "source": [
    "def make_table(yielddir, cat, histname):\n",
    "    norm_file = yielddir + cat + \"/\" + histname + \"_norm.json\"\n",
    "    normerror_file = yielddir + cat + \"/\" + histname + \"_normerror.json\"\n",
    "    \n",
    "    with open(norm_file, \"r\") as f:\n",
    "        norms = json.load(f)\n",
    "    with open(normerror_file, \"r\") as f:\n",
    "        normerrors = json.load(f)\n",
    "        \n",
    "    for key in norms.keys():\n",
    "        print (r\"{}: {:.2f} $\\pm$ {:.2f}\".format(key, norms[key], normerrors[key]))\n",
    "    \n",
    "def make_table_all(yielddir, histname):\n",
    "    cat_keys = [\"dipho\", \"1lep_0tau\", \"0lep_1tau\", \"1lep_1tau\", \"0lep_2tau\", \"2lep_0tau\"]\n",
    "    process_keys = [\"GJet\",\"QCD\",\"ttX\",\"ZG\",\"WG\",\"Diphoton\",\"bkg\",\"data\",\"signal\"]\n",
    "    \n",
    "    norms_allcats = {}\n",
    "    normerrors_allcats = {}\n",
    "    for cat in cat_keys:\n",
    "        norm_file = yielddir + cat + \"/\" + histname + \"_norm.json\"\n",
    "        normerror_file = yielddir + cat + \"/\" + histname + \"_normerror.json\"\n",
    "        with open(norm_file, \"r\") as f:\n",
    "            norms = json.load(f)\n",
    "        with open(normerror_file, \"r\") as f:\n",
    "            normerrors = json.load(f)\n",
    "        norms_allcats[cat] = norms\n",
    "        normerrors_allcats[cat] = normerrors\n",
    "    \n",
    "    print (\"|-\")\n",
    "    print (\"| |\", \"|\".join(cat_keys))\n",
    "    print (\"|-\")\n",
    "    print (\"|-\")\n",
    "    for process in process_keys:\n",
    "        row_content = []\n",
    "        for cat in cat_keys:\n",
    "            row_content.append('{:.2f} $\\pm$ {:.2f}'.format(norms_allcats[cat][process], normerrors_allcats[cat][process]) )\n",
    "        if process == \"bkg\" or process == \"signal\":\n",
    "            print (\"|-\")\n",
    "        print (\"| {} | {}\".format(process, \"|\".join(row_content)))\n",
    "    print (\"|-\")\n",
    "\n",
    "#make_table_all('/home/users/hmei/public_html/2021/2021-01-28_test/', \"pho_pT1\")\n",
    "make_table_all('/home/users/fsetti/public_html/HH2ggtautau/data_mc/2021-02-11_blind/', \"pho_pT1_v4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dipho\n",
      "data: 1435254.00 $\\pm$ 1198.02\n",
      "GJet: 623155.33 $\\pm$ 7275.42\n",
      "QCD: 697650.86 $\\pm$ 15135.22\n",
      "ttX: 6458.70 $\\pm$ 164.79\n",
      "ZG: 6515.72 $\\pm$ 55.39\n",
      "WG: 16094.15 $\\pm$ 156.48\n",
      "Diphoton: 290600.03 $\\pm$ 263.37\n",
      "VH: 167.77 $\\pm$ 0.53\n",
      "bkg: 1640642.56 $\\pm$ 16796.74\n",
      "signal: 625.64 $\\pm$ 0.57\n",
      "###\n",
      "0lep_1tau\n",
      "data: 16906.00 $\\pm$ 130.02\n",
      "GJet: 7575.98 $\\pm$ 743.52\n",
      "QCD: 5948.41 $\\pm$ 1410.16\n",
      "ttX: 171.34 $\\pm$ 20.21\n",
      "ZG: 208.51 $\\pm$ 9.53\n",
      "WG: 221.78 $\\pm$ 18.80\n",
      "Diphoton: 5025.94 $\\pm$ 30.89\n",
      "VH: 6.13 $\\pm$ 0.10\n",
      "bkg: 19158.10 $\\pm$ 1594.73\n",
      "signal: 192.77 $\\pm$ 0.32\n",
      "###\n",
      "0lep_2tau\n",
      "data: 21.00 $\\pm$ 4.58\n",
      "GJet: 0.00 $\\pm$ 0.00\n",
      "QCD: 0.00 $\\pm$ 0.00\n",
      "ttX: 0.19 $\\pm$ 0.26\n",
      "ZG: 6.98 $\\pm$ 1.44\n",
      "WG: -0.72 $\\pm$ 0.72\n",
      "Diphoton: 12.36 $\\pm$ 1.26\n",
      "VH: 0.10 $\\pm$ 0.01\n",
      "bkg: 18.90 $\\pm$ 2.06\n",
      "signal: 28.80 $\\pm$ 0.12\n",
      "###\n",
      "1lep_1tau\n",
      "data: 13.00 $\\pm$ 3.61\n",
      "GJet: 0.79 $\\pm$ 0.79\n",
      "QCD: 0.00 $\\pm$ 0.00\n",
      "ttX: 7.40 $\\pm$ 2.50\n",
      "ZG: 6.02 $\\pm$ 1.41\n",
      "WG: 1.86 $\\pm$ 1.35\n",
      "Diphoton: 2.37 $\\pm$ 0.54\n",
      "VH: 0.13 $\\pm$ 0.02\n",
      "bkg: 18.57 $\\pm$ 3.31\n",
      "signal: 32.08 $\\pm$ 0.13\n",
      "###\n",
      "2lep_0tau\n",
      "data: 160.00 $\\pm$ 12.65\n",
      "GJet: 1.08 $\\pm$ 1.08\n",
      "QCD: 0.00 $\\pm$ 0.00\n",
      "ttX: 20.03 $\\pm$ 7.70\n",
      "ZG: 159.77 $\\pm$ 8.09\n",
      "WG: -0.57 $\\pm$ 0.57\n",
      "Diphoton: 26.66 $\\pm$ 2.07\n",
      "VH: 2.37 $\\pm$ 0.06\n",
      "bkg: 209.35 $\\pm$ 11.43\n",
      "signal: 8.90 $\\pm$ 0.07\n",
      "###\n",
      "1lep_0tau\n",
      "data: 3798.00 $\\pm$ 61.63\n",
      "GJet: 629.30 $\\pm$ 185.40\n",
      "QCD: 1109.39 $\\pm$ 640.51\n",
      "ttX: 673.62 $\\pm$ 46.23\n",
      "ZG: 471.69 $\\pm$ 14.56\n",
      "WG: 873.21 $\\pm$ 36.08\n",
      "Diphoton: 501.94 $\\pm$ 9.93\n",
      "VH: 19.09 $\\pm$ 0.18\n",
      "bkg: 4278.24 $\\pm$ 669.61\n",
      "signal: 100.22 $\\pm$ 0.23\n",
      "###\n"
     ]
    }
   ],
   "source": [
    "yield_dir = \"/home/users/fsetti/public_html/HH2ggtautau/data_mc/2021-02-11_blind/\"\n",
    "for cat in cat_keys:\n",
    "    print (cat)\n",
    "    make_table(yield_dir, cat, \"pho_pT1_v4\")\n",
    "    print (\"###\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: 25040.00 \\pm 158.24\n",
      "GJet: 2957.11 \\pm 477.49\n",
      "ttbar: 0.72 \\pm 0.01\n",
      "ZG: 84.61 \\pm 0.43\n",
      "WG: 824.65 \\pm 39.05\n",
      "Diphoton: 4307.99 \\pm 57.79\n",
      "bkg: 8175.07 \\pm 482.56\n",
      "signal: 47.58 \\pm 0.17\n"
     ]
    }
   ],
   "source": [
    "make_table(\"/home/users/hmei/public_html/2021/2021-01-19_test/\", \"1lep_0tau\", \"n_lepton\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: 25040.00 \\pm 158.24\n",
      "GJet: 2941.66 \\pm 475.38\n",
      "ttbar: 1526.04 \\pm 61.19\n",
      "ZG: 9015.91 \\pm 73.49\n",
      "WG: 819.97 \\pm 38.83\n",
      "Diphoton: 949.82 \\pm 18.34\n",
      "bkg: 15253.41 \\pm 486.80\n",
      "signal: 47.57 \\pm 0.17\n"
     ]
    }
   ],
   "source": [
    "make_table(\"/home/users/hmei/public_html/2021/2021-01-19_test/\", \"1lep_0tau\", \"lepton_pT1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data: 25040.00 \\pm 158.24\n",
      "GJet: 2941.66 \\pm 475.38\n",
      "QCD: 749.65 \\pm 469.76\n",
      "ttbar: 1526.04 \\pm 61.19\n",
      "ZG: 9015.91 \\pm 73.49\n",
      "WG: 819.97 \\pm 38.83\n",
      "Diphoton: 949.82 \\pm 18.34\n",
      "bkg: 16003.06 \\pm 676.50\n",
      "signal: 47.57 \\pm 0.17\n"
     ]
    }
   ],
   "source": [
    "make_table(\"/home/users/hmei/public_html/2021/2021-01-19_test/\", \"1lep_0tau\", \"pho_pT1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hists/basic/1lep_1tau/signal/dR_tau_e.json\n",
      "hists/basic/1lep_1tau/signal/dR_tau_mu.json\n",
      "hists/basic/1lep_1tau/signal/electron_eta1.json\n",
      "hists/basic/1lep_1tau/signal/electron_iso1.json\n",
      "hists/basic/1lep_1tau/signal/electron_phi1.json\n",
      "hists/basic/1lep_1tau/signal/electron_pT1.json\n",
      "hists/basic/1lep_1tau/signal/mtaue.json\n",
      "hists/basic/1lep_1tau/signal/mtaumu.json\n",
      "hists/basic/1lep_1tau/signal/muon_eta1.json\n",
      "hists/basic/1lep_1tau/signal/muon_iso1.json\n",
      "hists/basic/1lep_1tau/signal/muon_phi1.json\n",
      "hists/basic/1lep_1tau/signal/muon_pT1.json\n",
      "hists/basic/1lep_1tau/signal/n_electron.json\n",
      "hists/basic/1lep_1tau/signal/n_muon.json\n",
      "hists/basic/1lep_1tau/signal/n_tau.json\n",
      "hists/basic/1lep_1tau/signal/pho_eta1.json\n",
      "hists/basic/1lep_1tau/signal/pho_eta2.json\n",
      "hists/basic/1lep_1tau/signal/pho_id1.json\n",
      "hists/basic/1lep_1tau/signal/pho_id2.json\n",
      "hists/basic/1lep_1tau/signal/pho_phi1.json\n",
      "hists/basic/1lep_1tau/signal/pho_phi2.json\n",
      "hists/basic/1lep_1tau/signal/pho_pT1.json\n",
      "hists/basic/1lep_1tau/signal/pho_pT2.json\n",
      "hists/basic/1lep_1tau/signal/pho_pTom1.json\n",
      "hists/basic/1lep_1tau/signal/pho_pTom2.json\n",
      "hists/basic/1lep_1tau/signal/tau_deeptau_vs_e_1.json\n",
      "hists/basic/1lep_1tau/signal/tau_deeptau_vs_j_1.json\n",
      "hists/basic/1lep_1tau/signal/tau_deeptau_vs_m_1.json\n",
      "hists/basic/1lep_1tau/signal/tau_eta1.json\n",
      "hists/basic/1lep_1tau/signal/tau_phi1.json\n",
      "hists/basic/1lep_1tau/signal/tau_pT1.json\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "ls hists/basic/1lep_1tau/signal/*json"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
